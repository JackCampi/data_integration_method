% =======================
%  Two-column paper style
% =======================
\documentclass[11pt,a4paper]{article}

% ---------- Language & encoding ----------
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

% ---------- Geometry ----------
\usepackage[a4paper,margin=1.5cm]{geometry}

% ---------- Fonts ----------
\usepackage{newtxtext,newtxmath} % Times-like academic font
\usepackage{microtype}

% ---------- Math ----------


% ---------- Figures / tables ----------
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{subcaption}

% ---------- Links / bibliography ----------
\usepackage[hidelinks]{hyperref}
\usepackage[numbers,sort&compress]{natbib}

% ---------- Section formatting ----------
\usepackage{titlesec}
\titleformat{\section}{\large\bfseries}{\thesection}{0.6em}{}
\titleformat{\subsection}{\normalsize\bfseries}{\thesubsection}{0.6em}{}
\titlespacing*{\section}{0pt}{1.0ex}{0.8ex}
\titlespacing*{\subsection}{0pt}{0.8ex}{0.6ex}

% ---------- Header ----------
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\lhead{\small Data integration for kidney transplantation}
\rhead{\small \thepage}
\renewcommand{\headrulewidth}{0.4pt}

% ---------- Abstract box ----------
\usepackage{framed}
\setlength{\FrameSep}{8pt}

% ---------- No indentation ----------
\setlength{\parindent}{0pt}
\setlength{\parskip}{4pt}
\setlength{\columnsep}{0.8cm}

% ==================================
%  Title
% ==================================
\title{\Large \textbf{Data Integration Methods and Application to Kidney Transplantation}\\
\vspace{0.3em}\normalsize Final Project -- Mathématiques Appliquées}

\author{
Angel ROMERO, Ana María PINZÓN
\thanks{École Centrale de Nantes, MATHAPPLI} \\
\small {École Centrale de Nantes}
\small {MATHAPPLI}
}

\date{\today}

\begin{document}


% ---------- Two-column title block ----------
\twocolumn[
\maketitle
\vspace{-1.0em}

\noindent\rule{\linewidth}{1.2pt}

\vspace{0.2em}
%\begin{center}
\small
\textbf{Keywords:} data integration, multi-view learning, transplantation, prediction
%\end{center}

%\vspace{0.2em}
% \begin{framed}
% \noindent\textbf{Abstract.}
% Dans ce rapport, nous étudions les méthodes d’intégration de données hétérogènes
% (cliniques, génétiques, biologiques) dans un cadre d’apprentissage supervisé.
% L’objectif est de construire un prédicteur du rejet humoral après transplantation
% rénale. Après une synthèse de la littérature, nous appliquons une méthode
% d’intégration spécifique et évaluons ses performances sur des données réelles.
% \end{framed}

\vspace{1.2em}
]

% ==================================
%  Content
% ==================================

\section{Introduction}


Predictive statistical models have not been used a lot historically
in the medical field due to the heterogeneity of the biological data.
This means, laboratories obtain different kind of informations from the same
individu such as xray images, molecular data, clinical data, etc.
This poses a problem for the unification in a single model, since the
data structures are very different in nature. To sum there is not great amounts of 
data available because there is no standarization in many lab procedures, 
and also because of the cost of collecting data, and even the ethical issues
that can arise from collecting data in the medical field. entre otros. This presents
a barrier for models which need a lot of observations to be statistically valid 
in the sense that they assume a huge amount of individuals to make valis inferences.

In this project we will work with data such as clinical data, demographic data, 
molecular data, etc. The problem here is how can we relate this variables if they
do not live in the same spaces. This a problem of multi-modal data integration.

Latest technologies in biology labs allow
for molecular data collection at levels we never 
had before. Nowadays, we talk about multi-omics data, which observes multiple biological phenotypes by levels of deepness from de the genetics to the phenomics (observable disfunction).

Another difficulty lies in the fact that there are not a lot of individuals in the data base but we do have access to information of different types for the same individual. 
We would like to see if we can get better predictions correctly relating this variables between them. (Discusion)

Bref,
For this project we are gonna discuss different ways of integrating multi-modal data
(taking into account their nature) in a prediction model and test them to see if we can get relatively good predictions for our specific problem of the rejection humoralafter kidney transplantation.

Why do we need data intégration tecniques? 
Naive approach :  Just having every variable as a simple covariate? 
Limitations (are they mathematical or simply it is not coherent with the problem?)
If its mathematical, why? (sum of distribution laws, ...)
If its coherence (Different type of data, correlation and causality,...)

\section{Data integration methods}

\subsection{First approach}

When talking about data integration from different sources, the first approach we can take in mind is to try sequential concatenation methods, being the basic one getting all information into a single complete matrix \cite{chen2023multiomics}. However, sometimes combining raw data cannot lead into better approximation as those methods do not model complex relationships between data across sources. 

Some approaches have been proposed, as a bayesian data integration method by Brooke L et al \cite{fridley2012bayesian}, where they build a bayes framework which uses path analysis in order to represent direct and indirect genomic effects on a phenotype. 

\textbf{EXPLICAR MATH}

Some others comprises linear combination among data sources, then they employ this new combination within the classical classification/regression models. For example, Prélot L. et al \cite{prelotYEARglycaemic} proposed the calculation of scores of Metabolic and Methylation data. 

Finally, even if some mechanisms have been postulated to fix the raw data concatenation problem, there still the "curse of dimensionality" as combining different scaled data can inflate hight-dimension. Thats why more complex models will be discussed on the next section.  

\subsection{Modern methods and research}
Kernel methods 

Others?

\subsubsection{Deep Learninng}

Deep Learning models have gained importance on the recent years, as they obtain satisfactory scores on complex data relationships modeling. through the years, some classical models have been adapted to the multi-modal learning problem, making the good enough to capture information from the same problem seen from different points of view. 

Even though those models can represent a good alternative to the problematic, it holds that the nature of the models keeps hard for the interpretation capacity of the phenomena, keeping them not really used, specially when taking health-related decisions. 

Here we discuss how to adapt the popular models when taking multiple source data, as just combining them cannot lead to the optimal improvement of the model \citep{yan2021deepmvl}.

\paragraph{Autoencoders}

 model was born as the main idea of encoding input pattern $X \in R^N$ into some reduced pattern $f(X) \in R^d$, with $ d\ll N$ \cite{rumelhart1986pdp}, where we will call $R^d$ the latent space and $f : R^N \rightarrow R^d$ the encoding function. Then we define $g : R^d \rightarrow R^N$ as the decoding function and the autoencoder problem can be expressed as \cite{baldi2012autoencoders}:

$$
\min_{f,g} \sum_{i}^N \| g \circ f (x_i) \| 
$$

Now, taking in mind the multi-modal data, some authors have proposed variations to the basic model. Here we present the bimodal Autoencoder proposed by Ngiam et al. \cite{Ngiam2011689} where they build the sequential model shown before:

IMAGEN

*Explicar maths *

However, there still another variations of the model, such as the Correlational AE proposed by BAE, Feng et al. \cite{feng2014crossmodal}, where they try to minimize the correlational learning error from each modal-data. Right before we find the $AE^2$ presented by Zhang et al. \cite{zhang2019ae2nets} witch takes two AE levels, the inner layer holds an AE for each data source and the outer manage the multi-modal integration. 

Further proposals present diverse variations. Among these, we find the cross-modal auto-encoder (CMAE), the margin sensitive (MSAE) and the convolutional AE \cite{yan2021deepmvl}.

\paragraph{Convolutional Neural Networks} 

were first presented by Yann LeCun et al \cite{lecun2015deep} as a high level feature representation. 

*Explicar maths *

When taking multiple sources, there can be stabilized two kinds of architectures: multi-modal-one-net model which integrates all data sequentially into a CNN and the one-modal-one-net model which creates separates CNN for each source and then fusion them with a deep layer, as shown in the figure \cite{yan2021deepmvl}

When using the one-modal-one-net mechanism we do not search to fusion the response of each model, but to include a combining mapping at the last convolutional layer. To this purpose, we define $f: x^{(i)}_n, x^{(j)}_n \rightarrow y_n$ as the fusion function. Christoph Feichtenhofer et al \cite{feichtenhofer2016twostream}. proposed and tested multiple ways of CNN fusion. Here we present some used mappings. 

\begin{table}[h]
\centering
\caption{Multi-modal CNN fusion functions}
\begin{tabular}{lcc}
\toprule
$f$ & math expression \\
\midrule
$y^{sum}_n$ & $y^d_n = x^{(i, d)}_n + x^{(j,d)}_n$ \\
$y^{max}_n$ & $y^d_n = \max(x^{(i, d)}_n, x^{(j,d)}_n)$ \\
$y^{cat}_n$ & $y^{2d}_n = x^{(i, d)}_n, y^{2d-1}_n = x^{(j,d)}_n$ \\
$y^{conv}_n$ & $y^{conv} = y^{cat} \ast F + b$ \\
\bottomrule
\end{tabular}
\end{table}

Note $d$ is the convolution chanel, as cat method represent the concatenation of two different channels. For the convolution, note $F$ represents the filter and $b$ the biases. 

\subsubsection{Probabilistic Approaches}
Inhomogeneous Poisson process
Bernoulli generalized linear models

\subsubsection{Linear models}

Generalized linear models:



\subsubsection{Kernel methods}





\section{Discussion}
Rigourus enough?

Precission? 

Risk : How much risk would be tolerable for decision making in the 
medical field?

Interpretability? In the medical field, the models have to be precise and have an
accurate argument for the prediction (i.e. which indicator and why is it having
that weight on the decision taken by the model)
Finally, in practice an important question would be, how implied should be
the doctor in the decision? Should it be a model completely autonomous? 

\section{Introduction}
La transplantation rénale est un traitement de référence de l’insuffisance rénale
terminale. Cependant, le rejet humoral demeure une cause majeure d’échec du greffon.
L’intégration de données multi-sources constitue un levier prometteur pour améliorer
les modèles prédictifs \citep{ghojogh2021rkhs}.

\section{Contexte et données}
\subsection{Sources de données}
Description des données cliniques, biologiques et génétiques utilisées, ainsi que
les étapes de pré-traitement.

\subsection{Problème de prédiction}
Définition de la variable cible, horizon temporel, métriques d’évaluation.

\section{Méthodes d’intégration de données}
\subsection{Synthèse bibliographique}
Early integration, late integration, intermediate integration, multi-view learning,
kernel methods, CCA, PLS, etc.

\subsection{Méthode retenue}
Description détaillée de la méthode choisie et justification.

\section{Résultats}
\subsection{Protocole expérimental}
Validation croisée, modèles de référence, réglage des hyperparamètres.

\subsection{Résultats quantitatifs}


\begin{table}[h]
\centering
\caption{Performances des modèles}
\begin{tabular}{lcc}
\toprule
Modèle & AUC & Accuracy \\
\midrule
Clinique seul & 0.71 & 0.68 \\
Intégration multi-vues & 0.79 & 0.74 \\
\bottomrule
\end{tabular}
\end{table}

\section{Discussion}
Analyse critique des résultats, limites de l’étude, interprétabilité.

\section{Conclusion et perspectives}
Résumé des contributions et pistes futures.

% ==================================
%  Bibliography
% ==================================
\bibliographystyle{unsrtnat}
\bibliography{references}

\end{document}
